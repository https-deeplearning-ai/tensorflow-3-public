{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYJqjq66JVQQ"
   },
   "source": [
    "# Basic transfer learning with cats and dogs data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oWuHhhcJVQQ"
   },
   "source": [
    "### Import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ioLbtB3uGKPX"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjfMJAHPJVQR"
   },
   "source": [
    "### Import modules and download the cats and dogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y23ucAFLoHop"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "data_file_name = \"catsdogs.zip\"\n",
    "download_dir = '/tmp/'\n",
    "urllib.request.urlretrieve(data_url, data_file_name)\n",
    "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
    "zip_ref.extractall(download_dir)\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNVXCUNUJVQR"
   },
   "source": [
    "Check that the dataset has the expected number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AwMoZHxWOynx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cat images: 12501\n",
      "Number of dog images: 12501\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of cat images:\",len(os.listdir('/tmp/PetImages/Cat/')))\n",
    "print(\"Number of dog images:\", len(os.listdir('/tmp/PetImages/Dog/')))\n",
    "\n",
    "# Expected Output:\n",
    "# Number of cat images: 12501\n",
    "# Number of dog images: 12501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0riaptkJVQR"
   },
   "source": [
    "Create some folders that will store the training and test data.\n",
    "- There will be a training folder and a testing folder.\n",
    "- Each of these will have a subfolder for cats and another subfolder for dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qygIo4W5O1hQ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('/tmp/cats-v-dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZHD_c-sJVQR"
   },
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "- The following code put first checks if an image file is empty (zero length)\n",
    "- Of the files that are not empty, it puts 90% of the data into the training set, and 10% into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M90EiIu0O314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is zero length, so ignoring.\n",
      "11702.jpg is zero length, so ignoring.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from shutil import copyfile\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[training_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "# Expected output\n",
    "# 666.jpg is zero length, so ignoring\n",
    "# 11702.jpg is zero length, so ignoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMx_pePuJVQR"
   },
   "source": [
    "Check that the training and test sets are the expected lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cl8sQpM1O9xK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training cat images 11250\n",
      "Number of training dog images 11250\n",
      "Number of testing cat images 1250\n",
      "Number of testing dog images 1250\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training cat images\", len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
    "print(\"Number of training dog images\", len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
    "print(\"Number of testing cat images\", len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
    "print(\"Number of testing dog images\", len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
    "\n",
    "# expected output\n",
    "# Number of training cat images 11250\n",
    "# Number of training dog images 11250\n",
    "# Number of testing cat images 1250\n",
    "# Number of testing dog images 1250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNz89__rJVQR"
   },
   "source": [
    "### Data augmentation (try adjusting the parameters)!\n",
    "\n",
    "Here, you'll use the `ImageDataGenerator` to perform data augmentation.  \n",
    "- Things like rotating and flipping the existing images allows you to generate training data that is more varied, and can help the model generalize better during training.  \n",
    "- You can also use the data generator to apply data augmentation to the validation set.\n",
    "\n",
    "You can use the default parameter values for a first pass through this lab.\n",
    "- Later, try to experiment with the parameters of `ImageDataGenerator` to improve the model's performance.\n",
    "- Try to drive reach 99.9% validation accuracy or better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TVO1l8vAPE14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "# Experiment with your own parameters to reach 99.9% validation accuracy or better\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=100,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WchwDzWNJVQR"
   },
   "source": [
    "### Get and prepare the model\n",
    "\n",
    "You'll be using the `InceptionV3` model.  \n",
    "- Since you're making use of transfer learning, you'll load the pre-trained weights of the model.\n",
    "- You'll also freeze the existing layers so that they aren't trained on your downstream task with the cats and dogs data.\n",
    "- You'll also get a reference to the last layer, 'mixed7' because you'll add some layers after this last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tiPK1LlMOvm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weights_file = \"inception_v3.h5\"\n",
    "urllib.request.urlretrieve(weights_url, weights_file)\n",
    "\n",
    "# Instantiate the model\n",
    "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
    "                                include_top=False,\n",
    "                                weights=None)\n",
    "\n",
    "# load pre-trained weights\n",
    "pre_trained_model.load_weights(weights_file)\n",
    "\n",
    "# freeze the layers\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3edBz_IxJVQR"
   },
   "source": [
    "### Add layers\n",
    "Add some layers that you will train on the cats and dogs data.\n",
    "- `Flatten`: This will take the output of the `last_layer` and flatten it to a vector.\n",
    "- `Dense`: You'll add a dense layer with a relu activation.\n",
    "- `Dense`: After that, add a dense layer with a sigmoid activation.  The sigmoid will scale the output to range from 0 to 1, and allow you to interpret the output as a prediction between two categories (cats or dogs).\n",
    "\n",
    "Then create the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oDidHXO1JVQR"
   },
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asCm8okXJVQR"
   },
   "source": [
    "### Train the model\n",
    "Compile the model, and then train it on the test data using `model.fit`\n",
    "- Feel free to adjust the number of epochs.  This project was originally designed with 20 epochs.\n",
    "- For the sake of time, you can use fewer epochs (2) to see how the code runs.\n",
    "- You can ignore the warnings about some of the images having corrupt EXIF data. Those will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3nxUncKWPRhR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "145/225 [==================>...........] - ETA: 47s - loss: 0.2246 - acc: 0.9131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/PIL/TiffImagePlugin.py:845: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 143s 619ms/step - loss: 0.2024 - acc: 0.9186 - val_loss: 0.0790 - val_acc: 0.9696\n",
      "Epoch 2/2\n",
      "225/225 [==============================] - 136s 603ms/step - loss: 0.1483 - acc: 0.9381 - val_loss: 0.0829 - val_acc: 0.9672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=RMSprop(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# train the model (adjust the number of epochs from 1 to improve performance)\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=validation_generator,\n",
    "            epochs=2,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6Oo6kM-JVQR"
   },
   "source": [
    "### Visualize the training and validation accuracy\n",
    "\n",
    "You can see how the training and validation accuracy change with each epoch on an x-y plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "erDopoQ5eNL7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKc_1Qm8JVQR"
   },
   "source": [
    "### Predict on a test image\n",
    "\n",
    "You can upload any image and have the model predict whether it's a dog or a cat.\n",
    "- Find an image of a dog or cat\n",
    "- Run the following code cell.  It will ask you to upload an image.\n",
    "- The model will print \"is a dog\" or \"is a cat\" depending on the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0R9fsf4w29e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(150, 150))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  image_tensor = np.vstack([x])\n",
    "  classes = model.predict(image_tensor)\n",
    "  print(classes)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a dog\")\n",
    "  else:\n",
    "    print(fn + \" is a cat\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
